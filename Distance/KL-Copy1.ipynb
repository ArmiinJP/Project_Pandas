{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e95f834-b6f4-4c10-818d-3b6322806f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65682770-2499-4aa9-9f82-f7f9db999e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pd.read_csv('dist_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8cfa07-6a71-4b2c-89cc-2d8b28356122",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_clean = dist[dist['dist'] != \"[[], []]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cf057cf-652a-44d1-9a70-ef1cad0f05f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dist_clean.iloc[:, :-1].values\n",
    "y = dist_clean.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1640004-950d-4e65-bca3-328047c43c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e40cd4c7-12ae-41df-a54d-8a18539ec879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sample(sample):\n",
    "    sample_list = sample[0].replace(', [', '; [').split(';')\n",
    "    sample_x = sample_list[0]\n",
    "    sample_Px = sample_list[1]\n",
    "\n",
    "    sample_x_list = []\n",
    "    sample_Px_list = []\n",
    "    \n",
    "    for x in sample_x.split(','):\n",
    "        sample_x_list.append(x.replace(' ', '').replace('[', '').replace(']', ''))\n",
    "    for Px in sample_Px.split(','):\n",
    "        sample_Px_list.append(Px.replace(' ', '').replace('[', '').replace(']', ''))\n",
    "\n",
    "    dict_sample = {}\n",
    "    for i in range(len(sample_x_list)):\n",
    "        dict_sample[sample_x_list[i]] = sample_Px_list[i]\n",
    "    return dict_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8494591-0ad1-4c0b-a29b-f8b7ea40f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_keys_dataset1_exist_in_dataset2(dataset1, dataset2, threshold):\n",
    "    count = 0\n",
    "    total = len(dataset1.keys())\n",
    "    for key in dataset1.keys():\n",
    "        if dataset2.get(key) is None:\n",
    "            pass\n",
    "        else:\n",
    "            count += 1\n",
    "\n",
    "    if (count/total) * 100 >= float(threshold):\n",
    "        #print(count, (count/total) * 100, float(threshold))\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cfc4e7b8-b860-4dc2-a692-697f121de47a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_distance(distance_func, min_precent_similarity):\n",
    "    #count = 0\n",
    "    result = []\n",
    "    for i, sample_x_test in enumerate(x_test): \n",
    "        result_zikma = []\n",
    "    \n",
    "        for j, sample_x_train in enumerate(x_train):\n",
    "            if all_keys_dataset1_exist_in_dataset2(clean_sample(sample_x_test), clean_sample(sample_x_train), min_precent_similarity):\n",
    "                Px_list = []\n",
    "                for xd1, Pxd1 in clean_sample(sample_x_test).items():\n",
    "                    if xd1 == \"\" or Pxd1 == \"\":\n",
    "                        continue\n",
    "                    Pxd2 = clean_sample(sample_x_train).get(xd1)\n",
    "                    if Pxd2 is None:\n",
    "                        Pxd2 = 0.0\n",
    "                    #print(xd1, Pxd1, Pxd2)\n",
    "                    Px_list.append([Pxd1, Pxd2])\n",
    "\n",
    "                \n",
    "                sum = distance_func(Px_list)\n",
    "                result_zikma.append([y_train[j], sum])\n",
    "                #print(sum)\n",
    "                \n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        result.append([sample_x_test ,result_zikma])\n",
    "        \n",
    "        # count += 1\n",
    "        # if count > 1:\n",
    "        #     break\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "339bf2ef-4886-4030-9673-7b14be0d4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def js(Px_list):\n",
    "    for i in Px_list:\n",
    "        Mx = (float(i[0]) + float(i[1]))/2\n",
    "        i.append(Mx)\n",
    "\n",
    "    PM_list = []\n",
    "    QM_list = []\n",
    "    for i in Px_list:\n",
    "        PM_list.append([i[0], i[2]])\n",
    "        QM_list.append([i[1], i[2]])\n",
    "\n",
    "    sum1 = kl(PM_list)\n",
    "    sum2 = kl(QM_list)\n",
    "\n",
    "    return (sum1 + sum2)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a2a6bdc-c54b-4de6-95d8-68fef469836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl(Px_list):\n",
    "    sum = 0 \n",
    "    for i in Px_list:\n",
    "        Pxd1 = i[0]\n",
    "        Pxd2 = i[1]\n",
    "        if float(Pxd1) == 0.0:\n",
    "            sum += 0.0\n",
    "            continue\n",
    "        sum += float(Pxd1) * math.log10(float(Pxd1) / float(Pxd2))\n",
    "        \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d5467de-3f55-4faa-a7cd-e9c972a33e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Predict_test1(all_distance_label, threshold):\n",
    "    # #using max\n",
    "    # y_pred = []\n",
    "    # for i in range(len(x_test)):\n",
    "    #     t = pd.DataFrame(final_result[i][1], columns=['Label', 'Kl Result'])\n",
    "    #     bests = t.value_counts()\n",
    "    #     if bests.size == 0:\n",
    "    #         y_pred.append(0)\n",
    "    #     else:\n",
    "    #         y_pred.append(bests.head(1).index[0][0])\n",
    "    # return y_pred\n",
    "\n",
    "# def Predict_test2(all_distance_label, threshold):\n",
    "    # #using sort\n",
    "    # y_pred = []\n",
    "    # for i in range(len(x_test)):\n",
    "    #     t = pd.DataFrame(final_result[i][1], columns=['Label', 'Kl Result'])\n",
    "    #     grouped_df = t.groupby(['Label', 'Kl Result']).size().reset_index(name='Count')\n",
    "    #     sorted_df = grouped_df.sort_values(by=['Count', 'Kl Result'], ascending=[False, True])\n",
    "    #     if t.values.size == 0:\n",
    "    #         y_pred.append(0)\n",
    "    #     else:\n",
    "    #         y_pred.append(sorted_df.head(1)['Label'].values[0])\n",
    "    # return y_pred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca98c1b0-2b7d-42bd-bf27-91bcd494df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(all_distance_label, threshold):\n",
    "    y_pred = []\n",
    "    for i in range(len(x_test)):\n",
    "        t = pd.DataFrame(all_distance_label[i][1], columns=['Label', 'Kl Result'])\n",
    "        tmp = t[t['Kl Result'] < threshold] #0.99 - 1.01\n",
    "        grouped_df = tmp.groupby(['Label']).size().reset_index(name='Count')\n",
    "        sorted_df = grouped_df.sort_values(by=['Count'], ascending=False)\n",
    "        \n",
    "        if tmp.values.size == 0:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(sorted_df.head(1)['Label'].values[0])\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f63cf179-8ab1-40ac-9057-7bdb7cbc8532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def diffrence_pred_test(y_pred, y_test):\n",
    "    test = []\n",
    "    count = 0\n",
    "    for i, value1 in enumerate(y_pred):\n",
    "        if value1 != y_test[i]:\n",
    "            test.append([i, value1, y_test[i]])\n",
    "            count+=1\n",
    "    \n",
    "    return pd.DataFrame(test, columns=['index', 'y_pred', 'y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d9a8fb47-c84f-456d-9235-76d0d6d6404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_percent_similarity():\n",
    "    final_result = []\n",
    "    for i in range(30, 101): # one or zero\n",
    "        final_result.append(calculate_distance(js, i))\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4446a650-c15b-4bfc-8b9f-19765ed1584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = other_percent_similarity()\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0c22bbc1-7aa6-4a7a-84bf-8acd0ebd1398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_result = calculate_distance(js, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "50e3420c-3b6f-47ce-9518-b667af527611",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Predict(final_result, 0.0999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9b1b7b8b-aad3-4ae7-b6b1-19414d23becc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>27525</td>\n",
       "      <td>27341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>27321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>27525</td>\n",
       "      <td>27523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>27525</td>\n",
       "      <td>27341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>27321</td>\n",
       "      <td>27525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1550</td>\n",
       "      <td>27525</td>\n",
       "      <td>27341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1551</td>\n",
       "      <td>0</td>\n",
       "      <td>27321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1561</td>\n",
       "      <td>27523</td>\n",
       "      <td>27321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1562</td>\n",
       "      <td>0</td>\n",
       "      <td>27525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1578</td>\n",
       "      <td>27525</td>\n",
       "      <td>27341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  y_pred  y_test\n",
       "0       11   27525   27341\n",
       "1       18       0   27321\n",
       "2       36   27525   27523\n",
       "3       44   27525   27341\n",
       "4       48   27321   27525\n",
       "..     ...     ...     ...\n",
       "150   1550   27525   27341\n",
       "151   1551       0   27321\n",
       "152   1561   27523   27321\n",
       "153   1562       0   27525\n",
       "154   1578   27525   27341\n",
       "\n",
       "[155 rows x 3 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffrence_pred_test(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f59cbd91-8aa0-49a9-ae97-cb1bf5720fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0   0   0   0   0   0   0   0]\n",
      " [  5 151   0   0   0   0   0   0]\n",
      " [ 12   0 359   0  20   8   0   0]\n",
      " [  0   0   0   0   0  26   0   0]\n",
      " [  2   8   8   0 252   8   0   0]\n",
      " [ 22   0  20   0   0 572   0   0]\n",
      " [ 11   0   0   0   5   0   1   0]\n",
      " [  0   0   0   0   0   0   0  92]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "       27311       0.95      0.97      0.96       156\n",
      "       27321       0.93      0.90      0.91       399\n",
      "       27341       0.00      0.00      0.00        26\n",
      "       27523       0.91      0.91      0.91       278\n",
      "       27525       0.93      0.93      0.93       614\n",
      "       27652       1.00      0.06      0.11        17\n",
      "       28090       1.00      1.00      1.00        92\n",
      "\n",
      "    accuracy                           0.90      1582\n",
      "   macro avg       0.71      0.60      0.60      1582\n",
      "weighted avg       0.92      0.90      0.91      1582\n",
      "\n",
      "Accuracy: 0.9020227560050569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arminjp/Documents/Project/pandas/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arminjp/Documents/Project/pandas/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arminjp/Documents/Project/pandas/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arminjp/Documents/Project/pandas/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arminjp/Documents/Project/pandas/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arminjp/Documents/Project/pandas/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "res = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(res)\n",
    "res1 = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (res1)\n",
    "res2 = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy:\",res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "58aa199d-88ea-4840-a7a3-a7ca0965189e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0   0   0   0   0   0   0   0]\n",
      " [  5 151   0   0   0   0   0   0]\n",
      " [  8   0 363   0  20   8   0   0]\n",
      " [  0   0   0   0   0  26   0   0]\n",
      " [  2   8   8   0 251   9   0   0]\n",
      " [ 20   0  54   0   0 540   0   0]\n",
      " [ 11   0   0   0   5   0   1   0]\n",
      " [  0   0   0   0   0   0   0  92]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "       27311       0.95      0.97      0.96       156\n",
      "       27321       0.85      0.91      0.88       399\n",
      "       27341       0.00      0.00      0.00        26\n",
      "       27523       0.91      0.90      0.91       278\n",
      "       27525       0.93      0.88      0.90       614\n",
      "       27652       1.00      0.06      0.11        17\n",
      "       28090       1.00      1.00      1.00        92\n",
      "\n",
      "    accuracy                           0.88      1582\n",
      "   macro avg       0.70      0.59      0.59      1582\n",
      "weighted avg       0.90      0.88      0.89      1582\n",
      "\n",
      "Accuracy: 0.8836915297092288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arminjp/Documents/Project/pandas/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arminjp/Documents/Project/pandas/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arminjp/Documents/Project/pandas/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arminjp/Documents/Project/pandas/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arminjp/Documents/Project/pandas/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arminjp/Documents/Project/pandas/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "res = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(res)\n",
    "res1 = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (res1)\n",
    "res2 = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy:\",res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676a612f-308a-4c4e-9230-0c20c534d6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
