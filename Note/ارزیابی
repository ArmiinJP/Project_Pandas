 قبلا بر اساس داده های train اومدید یک مدلی را train کردید.
 حالا میخواید روی داده های validation یا test این مدلتون را ارزیابی کنید.
 
متریک ها برای ارزیابی یک مدل چیا هستند؟
یکی بیاد بگه من یه مدلی نوشتم که میتونه متن های خوب را از متن های کنایه آمیز تشخیص بده.

یک مثال بهتر تشخیص سرطان افراد، فرد تست بده ما بگیم سرطان داری یا سالمی
اولین سوالی که میپرسیم ازش:
چند درصد دقت داره؟ آیا همین که دقتش بالا باشه کافیه؟
زمان؟ ما تو این درس درگیر زمان نیستیم خیلی.

چطوری دقت و حساب کنیم؟
تعداد نمونه‌هایی که درست پاسخ داده ام به کل نمونه‌هایی که گرفتم. عکس خوب
اگر x_test را دادی، میاد به تو y_test را هم میده، خب کل نمونه ها میشه y_test حالا من میام y_pred را هم برای تمامی x_test ها حساب میکنم، حالا من y_pred را دارم و y_test که تعدادشون هم یکی هست و مثلا n تاست ، میام مقایسه میکنم این دو را با هم تا ببینم چند تا از y_pred هام که گفتم درست بوده، فرض میشه b تا، خب کل نمونه هایی که داشتم n تا بوده، بنابراین دقت من اینجا اونهایی که درست گفتم به کل داده هایی که ازمایش کردم، که میشه b/n دقت من.

دقت به تنهایی جواب نیست ، شرکت اول و دوم که مثال زد سر بحث دقت.
بحث اینجاست که اون کسی که سرطان داره، خیلی برای ما مهم هست که از دستش ندیم. ولو اینکه چهار تا ادم سالم را بیاد بگه اشتباهی که سرطان داری.
تست غربالگری، یعنی کسی که بیمار هست را از دست ندیم ولو اینکه چهار نفر غیر بیمار هم به اشتباه در غربالگری اولیه بیان، نه این که از دم بریم بگیم هیشکی هیچیش نیست و ممکنه دقت خیلی خوبی هم پیدا بشه، ولی خب بیمارا به چخ میرند. پس در جدولی که داریم عدد سمت چپ بالا برای ما مهمتر هست نسیبت به سمت راست پایین.

داده های ما inbalance یا غیر متعادل هستند. اگه همه چیز پنجاه پنجاه باشه فرضا مثل تشخیص جنسیت جنین، بعد اون موقع یه تست بیاد ۹۵ درصد درست بگه، این تست خدایی خوبه، اما وقتی داده ها مثل همین بحث سرطان اینقدر اینبالانس هستند، و درصد سرطانی ها خیلی کمه، دقت دیگه ملاک خوبی نیست، چون یه تست شخمی که از دم میگه هیشکی سرطان نداره، با این که دقت خوبی خواهد داشت، چون در عمل داره تعداد زیادی را درست میگه و این به خاطر غیرمتعادل بودن دیتا هست، خب این به چه دردی میخوره.
پس باید بریم سراغ متریک های دیگه برای ارزیابی کلاسیفیشن
TP	FN
FP	TN
یک معیار خوب دیگه TP/TP+FN هست، که در واقع در مثالمون میشه، اگه طرف واقعا سرطان داشته، چند درصد ما درست گفتیم و درست کشف کرده تست من.در واقع صورت کسر من اونهایی هست که من درست گفتم مثبت هستند، مخرج من کل کسانی هستند که من باید میگفتم مثبت، یعنی هم اونهایی که واقعا مثبت بودند و من درست گفتم، هم اونهایی که من گفتم نیستند و غلط گفتم، و در واقع اونهام مثبت بودند، و من به اشتباه گفتم نیستند، پس در واقع میشه درصد کسانی که به درستی کشفشون کردیم، اگه FN ما زیاد بشه، یعنی به اشتباه گفتم نیستند، یعنی حساسیت من داره پایین میاد، و هر چی بیشتر باشه یعنی حساسیت مدل بیشتر هست برای همین به این نسیبت میگن sensitivity یه اسم دیگه هم میگن به اسم recall

یک معیار خوب دیگه TP/TP+FP هست، از افرادی که واقعا تشخیص دادیم که سرطان دارند، چند درصد واقعا مثبت هستند، یعنی اونهایی که واقعا درست تشخیص دادم مثبت هستند، به کل کسانی که گفتیم مثبت هستند. به این میگن percision.

فرق اولی و دومی را داشته باش، اولی کسایی که باید مثبت میگفتیم را میسنجیم که چند درصدشون را تشخیص دادیم.
دومی میگیم اوکی حالا از اینهایی که تشخیص دادی، که ممکن هم هست تو تست اول مثل ببر عمل کردی و از اتفاق همه کسایی که انتظار داشتیم تو بگی مثبت و گفتی، اما حالا باید یه پارامتر دیگه را هم بسنجیم، از بین این کسایی که گفتی مثبت، ممکنه افرادی هم بودند که تو به اشتباه مثبت تشخیص دادی، یعنی میخوایم حالا مثبتهایی که گفتی را تست کنیم ببینیم چند درصشون را درست گفتی اینجاست که معیار دوم میاد وسط
پس معیار اول انتظارات کسانی که باید مثبت میگفتی و تو تشخیصشون دادی را میسنجیم
و معیار دوم میایم از بین کسانی که تو حالا مثبت گفتی، میبینیم چند درصشون درست بودند.

پس در واقع اول میگیم چند درصد از افرادی که به این تست معرفی شدند ، ما آژیر زدیم براشون و حساسیت نشون دادیم. این میشه حساسیت مدل ما
و معیار بعدی میگه حالا از بین همه‌ی اینهایی که آژیر زدی چند درصدشون واقعا درست آزیر زدی و درست گفتی که بیماری دارند. این میشین پرسیژن مدل ما


یک معیار دیگه هم هست که میاد TN/TN+FP محاسبه میکنه که بهش میگیم specificity که اینم خوبه که میگه چه قدر مدل ما اسپسیفیک هست، یعنی الکی نمیاد چیزایی که فالس هستند را مثبت گزارش کنه این بحث دقیقا قرینه‌ی sencivity هست، اونجا میگفتیم چه قدر مدل ما حساسیت داره، و اینجا هم میشه گفت هر چی اسپسیفیک تر باشه یعنی بهتره، یعنی هی نیومده چرت و پرت به ما بگه، تو یه سری از جاها میان recall , specifity را میبینن و میگن این دو باید زیاد باشند.
یه سری جاها میان reacall , percision را میبنن .
اگر هم recall هم specifty جفتشون یک باشند، به این معنی هست که پرسیژن و هم دقت هم قطعا یک هستند، چون اون دو تا کاملا قرینه هستند و تنها در صورتی جفت یک میشند که همه چیز درست سر جاش باشه.

تو بحث خودمون خب ترنزکشن های ما بخش عمده اشون اوکی و سالم هستند، و تعداد خیلی کمی در کل ترنزکشن مخرب هستند، پس داده‌ی ما نامتعادل هست، پس جنسش مثل جنس بیماری سرطان هست، من میخوام ترنزکشن مخرب از دستم در نره و بتونم کشفش کنم، دقت در اینجا معیار خوبی نیست، اگه من بیام از دم بگم ترنزکشن سالم هست، به خاطر این که نامتعادل هست، خب در نهایت یه دقت خوبی از خودم به جا میزارم، ولی این چرته در عمل، من باید ببینم از بین ترنزکشن هایی که مخرب بودند، واقعا چندتاشون را تونستم تشخیص بدم، در واقع حساسیت مدل من نسبت به ترنزکشن مخرب و به تبع تشخیص اون چه قدر خوب بوده. فرض کن کلا ۱۰ تا ترنزکشن مخرب داشته باشیم و ۱۰۰۰ تا ترنزکشن سالم، مدلی خوبی که درصد بالایی از این ده تا مخرب را بتونه تشخیص بده، نه مدلی که این ده تا به چپش باشه، و بره همه را بگه سالم، درسته ۱۰۰۰ تا را درست خواهد گفت ولی گیر ما جایی دیگه بوده. پس حساسیت مهمه ، توجه بشه که این مهمتر هست برای ما یعنی این که بفهمیم طرف سرطان داره واقعا مهمه یا بفهمیم ترنزکشن مخرب هست واقعا مهمه، 
بحث مهم دیگه این هست که شخمی نیمم همه را بگیم مخرب، اینطوری حساسیت ما ۱۰۰ درصد میشه ، اما ما یه عالمه ترنزکشن سالم داریم که عین بز داریم میگیم مخرب هستیند. پس معیار دومی که به درد ما میخوره، این که بین اینهایی که اومدیم گفتیم مثبت، ببینیم چند درصدشون واقعا مخرب بودند، یعنی نسبت اونهایی که واقعا مخرب بودند را به کل اونهایی که آلارم زدی براشون بگیریم. یعنی TP ها به کل کسایی که گفتیم P یعنی هم  TP هم FP خب مسلما چیزی که اهمیت پیدا میکنه اگه تعداد FP زیاد بشه این کسر کوچیک میشه و این عدد پایین میاد، اما اگه تعداد FP کم و کمتر باشه، کسر در مجموع بزرگتر میشه و در بهترین حالت هم زمانی هست که FP صفر باشه، در این صورت یعنی هر چیزی که گفتیم P دقیقا همون مخرب بوده یعنی TP/TP که یعنی پرسیژن ما ۱۰۰ درصد بوده، پس در مجموع تستی خوبه که ریکالش ۱۰۰ درصد باشه، یعنی به موقع آلارم بزنه و پرسیژنش هم ۱۰۰ درصد باشه، یعنی توی اونهایی که آلارم زده، به درستی عمل کرده باشه. و درست تشخیص داده باشه.


یک معیار f1-score هم هست که اونم خوبه خدایی، که میشه 2*recall*percision تقسیم بر recall + percision به این میگن میانگین هارمونیک
روش های مختلف میانگین گیری تعریف میشه، بهش میگن میانگین های فیثاغورسی یکیش میانیگن ریاضیاتی هست که همون میانگین معروفه هست. یکی میانگین حسابی یکی میانگین هندسی هست یکی هم میانگین هارمونیک هست. که در این روش مثلا برای ۳ و ۵ و ۸ میاین ۱/۳ و ۱/۵ و ۱/۸ را با هم جمع میکنند تقسیم بر تعداد که سه هست میکنید و در نهایت به توان منهای یک میرسونید. که در عمل میشه تعداد تقسیم بر ۱/۳ + ۱/۵ + ۱/۸
اینجا که پرسژن و ریکال را داریم میریم میانگین هارمونیک میگیم یعنی ۲ را تقسیم بر ( ۱/ریکال + ۱/پرسیژن ) میکنیم و این میشه همون رابطه‌ی بالا. 
خب این عدد اگر یک باشه یعنی خیلی خوبه همه چی و خب در صورتی یک میشه که جفتشون یک باشند، و یه جور داره این دو تا را کنار هم دیگه نگاهشون میکنه
البته توجه بشه که ما گفتیم اول از همه اصولا ریکال مهمه برامون و در گام بعد میریم پرسیژن


همه را از دم نگاتیو بدیم، پرسیژن یک میشه ولی ریکال صفر میشه
همه را از دم پازیتیو بدیم، ریکال یک میشه ولی پرسیژن به چخ میره و صفر میشه
در این شرایط میبینم f1 از میانگین معمولی بهتره، چون میانیگن معمولی میشسه ۱+۰ تقسیم بر ۲ ولی در f1 در هر دو حالت صفر میشه یعنی چرته این معیار که میگی


z_score, p_value
