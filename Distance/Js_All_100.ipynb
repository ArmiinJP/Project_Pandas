{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e95f834-b6f4-4c10-818d-3b6322806f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65682770-2499-4aa9-9f82-f7f9db999e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pd.read_csv('dist_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a8cfa07-6a71-4b2c-89cc-2d8b28356122",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_clean = dist[dist['dist'] != \"[[], []]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cf057cf-652a-44d1-9a70-ef1cad0f05f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dist_clean.iloc[:, :-1].values\n",
    "y = dist_clean.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1640004-950d-4e65-bca3-328047c43c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e40cd4c7-12ae-41df-a54d-8a18539ec879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sample(sample):\n",
    "    sample_list = sample[0].replace(', [', '; [').split(';')\n",
    "    sample_x = sample_list[0]\n",
    "    sample_Px = sample_list[1]\n",
    "\n",
    "    sample_x_list = []\n",
    "    sample_Px_list = []\n",
    "    \n",
    "    for x in sample_x.split(','):\n",
    "        sample_x_list.append(x.replace(' ', '').replace('[', '').replace(']', ''))\n",
    "    for Px in sample_Px.split(','):\n",
    "        sample_Px_list.append(Px.replace(' ', '').replace('[', '').replace(']', ''))\n",
    "\n",
    "    dict_sample = {}\n",
    "    for i in range(len(sample_x_list)):\n",
    "        dict_sample[sample_x_list[i]] = sample_Px_list[i]\n",
    "    return dict_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8494591-0ad1-4c0b-a29b-f8b7ea40f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_keys_dataset1_exist_in_dataset2(dataset1, dataset2, threshold):\n",
    "    count = 0\n",
    "    total = len(dataset1.keys())\n",
    "    for key in dataset1.keys():\n",
    "        if dataset2.get(key) is None:\n",
    "            pass\n",
    "        else:\n",
    "            count += 1\n",
    "\n",
    "    if (count/total) * 100 >= float(threshold):\n",
    "        #print(count, (count/total) * 100, float(threshold))\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfc4e7b8-b860-4dc2-a692-697f121de47a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_distance(distance_func, min_precent_similarity):\n",
    "    # count = 0\n",
    "    result = []\n",
    "    for i, sample_x_test in enumerate(x_test): \n",
    "        result_zikma = []\n",
    "    \n",
    "        for j, sample_x in enumerate(x):\n",
    "            if all_keys_dataset1_exist_in_dataset2(clean_sample(sample_x_test), clean_sample(sample_x), min_precent_similarity):\n",
    "                Px_list = []\n",
    "                for xd1, Pxd1 in clean_sample(sample_x_test).items():\n",
    "                    if xd1 == \"\" or Pxd1 == \"\":\n",
    "                        continue\n",
    "                    Pxd2 = clean_sample(sample_x).get(xd1)\n",
    "                    if Pxd2 is None:\n",
    "                        Pxd2 = 0.0\n",
    "                    Px_list.append([Pxd1, Pxd2])\n",
    "                    \n",
    "                for xd2, Pxd2 in clean_sample(sample_x).items():\n",
    "                    if xd2 == \"\" or Pxd2 == \"\":\n",
    "                        continue\n",
    "                    Pxd1 = clean_sample(sample_x_test).get(xd2)\n",
    "                    if Pxd1 is None:\n",
    "                        Px_list.append([0.0, Pxd2])\n",
    "                \n",
    "                sum = distance_func(Px_list)\n",
    "                result_zikma.append([y[j], sum])\n",
    "                #print(Px_list, sum)\n",
    "                \n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        result.append([sample_x_test ,result_zikma])\n",
    "        \n",
    "        # count += 1\n",
    "        # if count > 10:\n",
    "        #     break\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "339bf2ef-4886-4030-9673-7b14be0d4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def js(Px_list):\n",
    "    for i in Px_list:\n",
    "        Mx = (float(i[0]) + float(i[1]))/2\n",
    "        i.append(Mx)\n",
    "\n",
    "    PM_list = []\n",
    "    QM_list = []\n",
    "    for i in Px_list:\n",
    "        PM_list.append([i[0], i[2]])\n",
    "        QM_list.append([i[1], i[2]])\n",
    "\n",
    "    sum1 = kl(PM_list)\n",
    "    sum2 = kl(QM_list)\n",
    "\n",
    "    return (sum1 + sum2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a2a6bdc-c54b-4de6-95d8-68fef469836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl(Px_list):\n",
    "    sum = 0 \n",
    "    for i in Px_list:\n",
    "        Pxd1 = i[0]\n",
    "        Pxd2 = i[1]\n",
    "        if float(Pxd1) == 0.0:\n",
    "            sum += 0.0\n",
    "            continue\n",
    "        sum += float(Pxd1) * math.log10(float(Pxd1) / float(Pxd2))\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca98c1b0-2b7d-42bd-bf27-91bcd494df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(all_distance_label, threshold):\n",
    "    y_pred = []\n",
    "    for i in range(len(x_test)):\n",
    "        t = pd.DataFrame(all_distance_label[i][1], columns=['Label', 'Kl Result'])\n",
    "        tmp = t[t['Kl Result'] < threshold] #0.99 - 1.01\n",
    "        grouped_df = tmp.groupby(['Label']).size().reset_index(name='Count')\n",
    "        sorted_df = grouped_df.sort_values(by=['Count'], ascending=False)\n",
    "        \n",
    "        if tmp.values.size == 0:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(sorted_df.head(1)['Label'].values[0])\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f63cf179-8ab1-40ac-9057-7bdb7cbc8532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def diffrence_pred_test(y_pred, y_test):\n",
    "    test = []\n",
    "    count = 0\n",
    "    for i, value1 in enumerate(y_pred):\n",
    "        if value1 != y_test[i]:\n",
    "            test.append([i, value1, y_test[i]])\n",
    "            count+=1\n",
    "    \n",
    "    return pd.DataFrame(test, columns=['index', 'y_pred', 'y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8276059c-a3a7-429d-a146-78cf62663619",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_js_full = calculate_distance(js, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecc6612a-ca58-4b06-9a38-b9c949882f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_js = Predict(final_result_js_full, 0.093) #good threshold 0.093"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee9bf22d-90cd-4614-a964-3138e90a2db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>27525</td>\n",
       "      <td>27341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>27525</td>\n",
       "      <td>27341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>27525</td>\n",
       "      <td>27341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>27525</td>\n",
       "      <td>27523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>27523</td>\n",
       "      <td>27652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1494</td>\n",
       "      <td>27523</td>\n",
       "      <td>27321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1517</td>\n",
       "      <td>27523</td>\n",
       "      <td>27321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1535</td>\n",
       "      <td>27525</td>\n",
       "      <td>27341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1549</td>\n",
       "      <td>27523</td>\n",
       "      <td>27652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1566</td>\n",
       "      <td>27523</td>\n",
       "      <td>27321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  y_pred  y_test\n",
       "0        9   27525   27341\n",
       "1       14   27525   27341\n",
       "2       23   27525   27341\n",
       "3       34   27525   27523\n",
       "4       40   27523   27652\n",
       "..     ...     ...     ...\n",
       "119   1494   27523   27321\n",
       "120   1517   27523   27321\n",
       "121   1535   27525   27341\n",
       "122   1549   27523   27652\n",
       "123   1566   27523   27321\n",
       "\n",
       "[124 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffrence_pred_test(y_pred_js, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59ab908e-4bad-410d-92f1-cf40ca8b81bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[131   0   0   2   0   0   0]\n",
      " [  0 331   0  23  30   0   0]\n",
      " [  0   0   0   1  38   0   0]\n",
      " [  1   5   0 283  14   0   0]\n",
      " [  0   1   0   1 594   0   0]\n",
      " [  0   0   0   8   0  17   0]\n",
      " [  0   0   0   0   0   0 102]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       27311       0.99      0.98      0.99       133\n",
      "       27321       0.98      0.86      0.92       384\n",
      "       27341       0.00      0.00      0.00        39\n",
      "       27523       0.89      0.93      0.91       303\n",
      "       27525       0.88      1.00      0.93       596\n",
      "       27652       1.00      0.68      0.81        25\n",
      "       28090       1.00      1.00      1.00       102\n",
      "\n",
      "    accuracy                           0.92      1582\n",
      "   macro avg       0.82      0.78      0.79      1582\n",
      "weighted avg       0.90      0.92      0.91      1582\n",
      "\n",
      "Accuracy: 0.9216182048040455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arminjp/Documents/Project/pandas/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arminjp/Documents/Project/pandas/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arminjp/Documents/Project/pandas/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "res1 = confusion_matrix(y_test, y_pred_js)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(res1)\n",
    "res11 = classification_report(y_test, y_pred_js)\n",
    "print(\"Classification Report:\",)\n",
    "print (res11)\n",
    "res12 = accuracy_score(y_test,y_pred_js)\n",
    "print(\"Accuracy:\",res12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea14485-b200-457b-8559-e9d551d01f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
